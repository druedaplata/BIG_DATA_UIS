{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 06A - Pig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Word count parcial\n",
    "\n",
    "obtén las 10 primeras tuplas de la variable `word_groups` del ejemplo de word count de las notas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%script pig -x local -4 files/piglog4j.properties\n",
    "\n",
    "<TU CODIGO AQUI>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Word count sobre Hadoop\n",
    "\n",
    "ejecuta el ejemplo de word count de las notas sobre Hadoop. Para ello:\n",
    "\n",
    "#### apaga algunos servicios para liberar memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!sudo service ambari-agent stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!sudo service ambari-server stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### asegúrate de que hadoop y hdfs están funcionando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!sudo hadoop-start-yarnmr.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!sudo hadoop-start-hdfs.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ahora ejecuta el script sobre Hadoop\n",
    "\n",
    "- fíjate que ejecutamos pig sin el parámetro `-x local`\n",
    "- transfiere el directorio `data/texts` a HDFS.\n",
    "- asegúrate de que el directorio de salida `pig_output` no exista.\n",
    "- cambia el comando `LOAD` para que se refiera al path correcto en HDFS.\n",
    "- elimina el comando `DUMP` y usa el siguiente comando para determinar el lugar en HDFS donde se guarda la salida.\n",
    "\n",
    "      STORE ordered_word_count INTO pig_output;\n",
    "\n",
    "- incluye en el notebook \n",
    "   - una muestra del contenido de los ficheros producidos. para esto tendrás que traerte desde hdfs los ficheros de salida.\n",
    "   - un pantallazo del [monitoring de Hadoop](http://localhost:19888) donde se vea la ejecución del script sobre map-reduce."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### copiamos los ficheros de entrada en HDFS y nos aseguramos que el directorio de salida no existe\n",
    "(probablemente de una ejecución anterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -copyFromLocal data/texts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -rm -r pig_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define el script y ejecútalo sobre Hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%script pig -4 files/piglog4j.properties\n",
    "\n",
    "<TU CODIGO AQUI>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vemos que efectivamente hay algo en el directorio de salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -ls pig_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### eliminamos la copia local del directorio de salida \n",
    "(si es que existe de una ejecución anterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -rf pig_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define y ejecuta el comando para traerte la salida generada en HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "<TU CODIGO AQUI>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### inspeccionamos parte del contenido de la salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!head -10 pig_output/part*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
